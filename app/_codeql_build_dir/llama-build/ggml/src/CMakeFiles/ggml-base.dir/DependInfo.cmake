
# Consider dependencies only in project.
set(CMAKE_DEPENDS_IN_PROJECT_ONLY OFF)

# The set of languages for which implicit dependencies are needed:
set(CMAKE_DEPENDS_LANGUAGES
  )

# The set of dependency files which are needed:
set(CMAKE_DEPENDS_DEPENDENCY_FILES
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-alloc.c" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-quants.c" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml.c" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o.d"
  "" "llama-build/ggml/src/ggml-base_autogen/timestamp" "custom" "llama-build/ggml/src/ggml-base_autogen/deps"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-backend.cpp" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/_codeql_build_dir/llama-build/ggml/src/ggml-base_autogen/mocs_compilation.cpp" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-base_autogen/mocs_compilation.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-base_autogen/mocs_compilation.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-opt.cpp" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-threading.cpp" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml.cpp" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/gguf.cpp" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o.d"
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_LINKED_INFO_FILES
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_FORWARD_LINKED_INFO_FILES
  )

# Fortran module output directory.
set(CMAKE_Fortran_TARGET_MODULE_DIR "")
