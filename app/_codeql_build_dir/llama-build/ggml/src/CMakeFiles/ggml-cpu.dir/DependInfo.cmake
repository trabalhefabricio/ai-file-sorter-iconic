
# Consider dependencies only in project.
set(CMAKE_DEPENDS_IN_PROJECT_ONLY OFF)

# The set of languages for which implicit dependencies are needed:
set(CMAKE_DEPENDS_LANGUAGES
  )

# The set of dependency files which are needed:
set(CMAKE_DEPENDS_DEPENDENCY_FILES
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/arch/x86/quants.c" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/quants.c" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o.d"
  "" "llama-build/ggml/src/ggml-cpu_autogen/timestamp" "custom" "llama-build/ggml/src/ggml-cpu_autogen/deps"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/arch/x86/repack.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/hbm.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/ops.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/repack.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/traits.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/include/external/llama.cpp/ggml/src/ggml-cpu/vec.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o.d"
  "/home/runner/work/ai-file-sorter-iconic/ai-file-sorter-iconic/app/_codeql_build_dir/llama-build/ggml/src/ggml-cpu_autogen/mocs_compilation.cpp" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu_autogen/mocs_compilation.cpp.o" "gcc" "llama-build/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu_autogen/mocs_compilation.cpp.o.d"
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_LINKED_INFO_FILES
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_FORWARD_LINKED_INFO_FILES
  )

# Fortran module output directory.
set(CMAKE_Fortran_TARGET_MODULE_DIR "")
